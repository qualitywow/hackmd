# An ICN/SDN-Based Network Architecture and Efficient Content Retrieval for Future Satellite-Terrestrial Integrated Networks
## Scenario
### Control Plane
GEOs: Master Controller
GEO coverage大、對地靜止
管理LEO、負責計算routing strategy、更新cachng strategy、做mobility management
maintain到在地面網路運作控制中心(NOCC)的connection

NOCC: 在地上
根據GEO給的報告，監控網路狀態，必要的時候替GEO執行複雜的運算
controller(GEO、MEO)間ctrl msg的routing strategy由NOCC real-time分配

### Forwarding Plane
因LEO不能時時刻刻連到地面GW，但又要善用衛星資源、同時保持低延遲，所以用MEO負責forward資料
MEOs: Assistant Controller
每個MEO都有一條backhaul的路連向地面GW，和地面網路相通 => MEO可以向GW取回(retrieve)任何Internet content
GEO(master ctrller)、NOCC可以下cmd要MEO負責部分controller的工作

### Access Plane
就LEO，但LEO走很快，如果資料還沒傳完就換手，controller要負責指引接下來的傳輸


### On-board Switch

Cache Region ______________
	Content Store: 把檔案暫存起來
	Request Table: 存哪個檔案被要幾次
	*把這兩者也視為Flow Table
	*佔用固定的儲存空間，但可以被controller動態調整、回收
_________________________

根據match-and-action機制，設計一個支援routing-by-name的flow table pipeline
封包先去Classigiacation Table做分類，會分成Interest/Data Packet，各自進去Interest/Data Pipeline

假設Interest Flow Table有M+1個flow entry，前M個各自對應Content Store中的前M項內容
	如果第M+1個Interest Packet有match到Interest Flow Table其中一個flow entry，Switch會回傳放在Content Store裡面的資料
	否則，最後一個flow entry的priority是最低的，......，Interest Packet會被forward到最近的MEO(Assist Ctrller)，以便從GW拿資料

Data Packet，Switch會先去Cache Strategy Table查一下，再決定要不要存到Content Store裡面。
	如果Data Packet有match到Cache Strategy Table中flow entries的一個，把現在Content Store中priority最低的content抽換掉
	接著，不管剛剛有沒有中(or 不管剛剛來的Data Packet有沒有被cache起來)，Data Packet都會到Pending Interest Table裡

(還沒處理完的Interest)
Pending Interest Table中，每個Data Packet都要和Interest Flow Table中的一個flow entry對到，並用Directed Diffusion走回source(要這個data的user)
一般來講，Pending Interest Table的內容應和Interest Flow Table中的內容匹配，若發生錯誤導致Packet和Table沒對到，封包會被Switch送到GEO

Interest Flow Table      <----->  Content Store的狀態
Pending Interest Table  <----->  收到Interest Packet的interface

?????
POF中對flow table的實作沒有限定，所以作者採用On-board Switch中共享table資源
Switch和Controller間的控制封包可以用OpenFlow中預設的Transport Layer安全協定(SSL)，Switch可用預先共享的key exchange來認證entity


## COOPERATIVE CONTENT RETRIEVAL SCHEME with one-hop neighbor cache sharing

User1跟LEO1要A、B、C，但LEO1沒有cache這些檔案，所以把request forward給MEO，MEO向GW要這些檔案
GW給MEO檔案後，MEO把檔案forward給LEO，LEO再給到User1
同時，LEO會根據Cache Strategy Table把要cache的東西留在自己身上，假設LEO有把A cache起來

若接下來User2向LEO2要檔案A，此request會被forward到LEO1，LEO1會回傳A給LEO2，LEO2再給到User2
> 我的想法：request會先從LEO2往AC走，AC知道現在誰cache什麼，所以AC把request給到LEO1

> 作者說：User2的request會走ISL到LEO1，作者的說法少經過一層，但DD可以說得通

是否表示：相鄰的LEO知道彼此身上存了什麼內容 or ISL broadcast所以LEO1回應說自己有A?
=> 作者2 hop，本來3 hops => one-hop neighbor cache sharing?

### Cooperative Content Retrieval Procedure

因為Backhaul Link有bandwidth限制 => 設定MEO的aggregation window $T_a$
$T_a$: 收到第一個request之後，會聽多久 => 這段時間讓MEO可以蒐集一些request，避免重複傳輸

假設LEO的Cache Strategy是要LEO1存A、B、C，LEO2存B、C、D。系統初始時，LEO都沒有cache任何東西

1. 根據歷史紀錄中每個檔案的熱門程度，GEO會送control message去改LEO1、LEO2的Cache Strategy Table中的flow table。
2. User1送request給LEO1，向LEO1要A、B、C。LEO1把request forward給MEO。
3. User2送request給LEO2，向LEO2要A。LEO2把request forward給MEO。
4. 假設經過的時間在$T_a$以內，所以這4個request都被MEO蒐集起來，包成1個request forward到GW。
5. 拿到A、B、C，MEO把檔案forward給LEO1、LEO2。
6. LEO1把A、B、C給User1，A、B、C；LEO2把A給User2。
7. MEO知道GEO訂定的Cache Strategy，所以在把A、B、C給LEO1後，會送control message給LEO2去改它的Forward Table，把有關A、B、C的routing strategy改掉。
8. User2送request給LEO2，向LEO2要B。因為routing strategy中寫到如果要B的話，跟LEO1拿，所以把request forward給LEO1。
9. LEO1把B給LEO2，LEO2根據Cache Ctrategy Table把B給cache起來，LEO2把B給User2。
10. 因為B不是從MEO來的，LEO2 cache住B之後，送status report告訴MEO說自己的Cache Store有更新。這樣能讓MEO保持對所有LEO的全知狀態。

- GEO每$T_c$會向LEO要status report，LEO要立刻回報Content Store的檔案熱門度
- GEO會再更新Cache Strategy Table中的flow table

## Improved Caching Schemes for Efficient Content Retrieval

### Cooperative Caching Scheme
NDN中常用兩種暫存策略：
- Least Recently Used (LRU)
- Least Frequenty Used (LFU)
這兩種是用在不知道檔案受歡迎程度的場景

但因為
- LEO動很快，coverage會一直變
- 檔案受歡迎的程度不平均
- User喜好的差異
所以在不同的地區會有有各種不同的content request和content popularity
用這樣的策略會導致cache得常常更新

因為MS可以知道哪些檔案常用、被暫存在哪裡，所以「在不同地區的user request多樣性」是現在比較推崇的策略。作者提出的方法是想要增加此架構中的caching gain。

1. 先把地球切成幾個區域，分別記錄檔案在這些區域的熱門度
2. 檔案$i$在地區$n$的熱門度表示成$p_{in} = \frac{R_{it}}{\Sigma_{t \in T_n^s} R_{it}}$
$T_n^s$: 衛星$s$服務地區$n$的時長，$\Sigma_{t \in T_n^s} R_{it}$: 檔案$i$的歷史request數

- 考慮使用者偏好，提出了一個relay caching method來減少cache update的頻率
    當一個LEO要離開一個區域，controller會通知LEO開始做caching update。
    <!-- LEO2要離開Area2到Area1；因為上一個服務Area1的是LEO1，所以LEO2會在GEO的協調下送一個request給LEO1去要他cache住的東西。 -->

    1. GEO先送一個control message去更新LEO2的caching strategy、routing strategy。
    2. LEO2生成相對應個request去跟LEO1要被LEO1暫存著的東西。
    在區域劃分均等的情況下，給個LEO都可以在GEO的協調下做caching update，此過程只用了ISL，減少Backhaul Link的使用。
    *Backhaul Link: GW-LEO
- 考慮檔案熱門程度不均勻，提出了一個cooperative caching strategy
    依據使用者的request數量，可以分成popular area和ordinary area
    為了要最大程度的減少STIN的流量負荷，此方法主要考慮popular area的暫存需求，
    => 服務ordinary area的LEO要幫服務popular area的LEO暫存一些檔案，但只限one-hop。
### Coded Caching Scheme
Coded Caching Scheme可以大量節省傳輸的traffic load。
MEO有一個aggregation window在收request，拿這些request去跟GW要檔案之後，可以把這些檔案做點整合。
圖5(b)中，MEO本來要分別傳三個不同的檔案給三個User，但改送$A \oplus B \oplus C$、$A \oplus B$，
LEO可以輕鬆解出自己要的檔案，MEO傳輸也可以省$\frac{1}{3}$頻寬。

## Performance Evaluation
- 5 LEO (Access Satellite)
- 1000 files in Content Library，在每個區域的檔案熱門度符合Zipf distribution
- 第$i$熱門的檔案被request的機率$= \frac{1}{i^{\alpha}}$，與$\alpha$成正比
- User request符合Poisson distribution
- 要實驗這個架構可以在ISL、ILL、Backhaul Link節省多少流量

### 4 Schemes
- Local Popularity First (LPF): 
cache在自身coverage中最受歡迎的檔案
- Neighbor Content Retrieval Enabled LPF (NLPF): 
cache在自身coverage中最受歡迎的檔案，並允許one-hop鄰居共享cache
- Cooperative Caching Strategy (CCS): 
考慮每個區域的熱門度、request數，允許one-hop鄰居共享cache，試圖找一個global optimal caching solution
- Coded Caching Enabled CCS (CC): 
MEO會在aggregation window蒐集request，在回傳檔案時找機會做network coding(XOR)

### Figure 6(a)
LPF當作baseline，NLPF的表現都比baseline好；因為允許one-hop鄰居共享cache。
隨著$\alpha$越大，節省的流量的差異就漸漸不見；因為$\alpha$大到某個程度之後，每個檔案的機率就沒差那麼多了

### Figure 6(b)
cache size和節省的流量成正比，NLPF因為one-hop鄰居共享，hit rate更大。
CC因為考慮整體的cache內容且做了network coding，改進的幅度隨著cache加大而增加(12.5%)

## Conclusion
(translator)
在本文中，我們提出了一種新穎的基於ICN / SDN的體系結構，它可以更好地應對未來的挑戰，例如快速增加的訪問請求和異構網絡的管理。因此，它為STIN的未來設計提供了可能的方向。我們專注於內容檢索應用程序，它為Internet貢獻了最多的流量，並提出了一種簡單而有效的協作內容檢索方案。通過採用協同緩存和編碼緩存，該方案可以在流量節省方面實現進一步的性能提升。在這種情況下，提出的啟發式方案對於STIN中實際內容檢索方案的設計具有指導意義。